{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariya-kislicyna/ML_DS22/blob/main/sem2_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Первое домашнее задание. \n",
        "Мягкий дедлайн: 3 мая, жесткий дедлайн: 10 мая. \n",
        "\n",
        "Максимальное количество баллов - 30. "
      ],
      "metadata": {
        "id": "uJKfiLSyexN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 1** (10 баллов) \n",
        "\n",
        "Рассмотрите две выборки: https://archive.ics.uci.edu/ml/datasets/Shill+Bidding+Dataset и https://archive.ics.uci.edu/ml/datasets/Speaker+Accent+Recognition. Для обоих выборок постройте AdaBoost, GradientBoosting, RandomForest, Bagging. Сравните качество на обоих выборках. Отличается ли результат? Почему? "
      ],
      "metadata": {
        "id": "5qOmhvfOVlG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "xivYbFHtoXz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "JCNhlscHohLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqdZAeBJ1mY5",
        "outputId": "f4ca0e99-fb14-4384-e7b0-abe921eee45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shill_data = pd.read_csv('/content/drive/MyDrive/Datasets/Shill_Bidding_Dataset.csv')\n",
        "X1 = shill_data.drop('Class', axis=1)\n",
        "y1 = shill_data['Class']"
      ],
      "metadata": {
        "id": "dDhPodXsokzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speaker_data = pd.read_csv('/content/drive/MyDrive/Datasets/accent-mfcc-data-1.csv')\n",
        "X2 = speaker_data.drop('language', axis=1)\n",
        "y2 = speaker_data['language']"
      ],
      "metadata": {
        "id": "J4wn5ntRooD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot кодирование категориальных переменных\n",
        "X1 = pd.get_dummies(X1)"
      ],
      "metadata": {
        "id": "hRhCis3Rop52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Делим данные на обучающие и тестовые выборки\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "yG_7zpL8otJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Построение моделей AdaBoost для обоих наборов данных\n",
        "ada1 = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "ada2 = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Обучение модели AdaBoost на тренировочных данных\n",
        "ada1.fit(X1_train, y1_train)\n",
        "ada2.fit(X2_train, y2_train)\n",
        "\n",
        "# Делаем прогноз на тестовом наборе данных для обоих датасетов\n",
        "y1_pred_ada = ada1.predict(X1_test)\n",
        "y2_pred_ada = ada2.predict(X2_test)\n",
        "\n",
        "# Рассчитываем точность для моделей AdaBoost на обоих наборах данных\n",
        "print(\"Accuracy on Shill Bidding Dataset:\")\n",
        "print(\"AdaBoost:\", accuracy_score(y1_test, y1_pred_ada))\n",
        "print(\"Accuracy on Speaker Accent Recognition Data Set:\")\n",
        "print(\"AdaBoost:\", accuracy_score(y2_test, y2_pred_ada))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abbnq4Bco7Q0",
        "outputId": "cf2c186d-f5ab-48cf-cc28-1a66bfd98379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Shill Bidding Dataset:\n",
            "AdaBoost: 0.9978914074855034\n",
            "Accuracy on Speaker Accent Recognition Data Set:\n",
            "AdaBoost: 0.5050505050505051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Построение модели Gradient Boosting для обоих наборов данных\n",
        "gb1 = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb2 = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Обучение моделей градиентного бустинга на тренировочных данных\n",
        "gb1.fit(X1_train, y1_train)\n",
        "gb2.fit(X2_train, y2_train)\n",
        "\n",
        "# Делаем прогноз на тестовом наборе данных для обоих датасетов\n",
        "y1_pred_gb = gb1.predict(X1_test)\n",
        "y2_pred_gb = gb2.predict(X2_test)\n",
        "\n",
        "# Рассчитываем точность для моделей Gradient Boosting на обоих наборах данных\n",
        "print(\"Accuracy on Shill Bidding Dataset:\")\n",
        "print(\"Gradient Boosting:\", accuracy_score(y1_test, y1_pred_gb))\n",
        "print(\"Accuracy on Speaker Accent Recognition Data Set:\")\n",
        "print(\"Gradient Boosting:\", accuracy_score(y2_test, y2_pred_gb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0hpJBfeiv1X",
        "outputId": "4676af22-9e28-49d1-a014-4ace28f076d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Shill Bidding Dataset:\n",
            "Gradient Boosting: 0.9968371112282551\n",
            "Accuracy on Speaker Accent Recognition Data Set:\n",
            "Gradient Boosting: 0.7171717171717171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Построение модели Random Forest для обоих наборов данных\n",
        "rf1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Обучение моделей Random Forest на обучающих данных\n",
        "rf1.fit(X1_train, y1_train)\n",
        "rf2.fit(X2_train, y2_train)\n",
        "\n",
        "# Делаем прогноз на тестовом наборе данных для обоих датасетов\n",
        "y1_pred_rf = rf1.predict(X1_test)\n",
        "y2_pred_rf = rf2.predict(X2_test)\n",
        "\n",
        "# Рассчитываем точность для моделей Random Forest на обоих наборах данных\n",
        "print(\"Accuracy on Shill Bidding Dataset:\")\n",
        "print(\"Random Forest:\", accuracy_score(y1_test, y1_pred_rf))\n",
        "print(\"Accuracy on Speaker Accent Recognition Data Set:\")\n",
        "print(\"Random Forest:\", accuracy_score(y2_test, y2_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Up2ywoqpLy0",
        "outputId": "7b19e640-a67b-400b-fd61-4baceccf2e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Shill Bidding Dataset:\n",
            "Random Forest: 0.9820769636267791\n",
            "Accuracy on Speaker Accent Recognition Data Set:\n",
            "Random Forest: 0.7676767676767676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определяем base estimator (дерево решений)\n",
        "base_estimator = DecisionTreeClassifier()\n",
        "\n",
        "# Построение классификатора BaggingClassifier\n",
        "bag1 = BaggingClassifier(base_estimator=base_estimator, n_estimators=100, random_state=42)\n",
        "bag2 = BaggingClassifier(base_estimator=base_estimator, n_estimators=100, random_state=42)\n",
        "\n",
        "# Обучаем модели на тренировочных данных\n",
        "bag1.fit(X1_train, y1_train)\n",
        "bag2.fit(X2_train, y2_train)\n",
        "\n",
        "# Делаем прогноз на тестовом сете для обоих наборов данных\n",
        "y1_pred_bag = bag1.predict(X1_test)\n",
        "y2_pred_bag = bag2.predict(X2_test)\n",
        "\n",
        "# Рассчитываем точность\n",
        "print(\"Accuracy on Shill Bidding Dataset:\")\n",
        "print(\"Bagging:\", accuracy_score(y1_test, y1_pred_bag))\n",
        "print(\"Accuracy on Speaker Accent Recognition Data Set:\")\n",
        "print(\"Bagging:\", accuracy_score(y2_test, y2_pred_bag))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hht4f9GumEY6",
        "outputId": "cef4e7c5-157c-49b1-cfb6-6d5b5fdfb184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Shill Bidding Dataset:\n",
            "Bagging: 0.9978914074855034\n",
            "Accuracy on Speaker Accent Recognition Data Set:\n",
            "Bagging: 0.7575757575757576\n"
          ]
        }
      ]
    },
     {
      "cell_type": "markdown",
      "source": [
        "**Вывод \n",
        "\n",
        "Качество может отличаться по нескольким причинам: различные характеристики в датасетах (напимер, разный размер, тип и кол-во признаков), различия в подходах к построению моделей (AdaBoost, GradientBoosting, RandomForest и Bagging ведут себя по-разному на различных данных). Также различия могут происходить из-за предобработки данных и подготовке для обучения модели."
      ],
      "metadata": {
        "id": "ad3cKziyVmcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод \n",
        "\n",
        "Получите оценку параметров нормального распределения из принципа максимума правдоподобия.\n"
      ],
      "metadata": {
        "id": "ad3cKziyVmcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценить распределения 𝑝(x ∣ $𝐶_𝑘$) можно с помощью метода максимального правдоподобия.\n",
        ">\n",
        "Рассмотрим пример: два класса, гауссианы с одинаковой матрицей ковариаций, и есть 𝐷 = $\\{x_𝑛, 𝑡_𝑛\\}^𝑁_{𝑛=1}$,\n",
        "где $𝑡_𝑛$ = 1 значит $𝐶_1$, $𝑡_𝑛$ = 0 значит $𝐶_2$\n",
        ">\n",
        "Обозначим 𝑝($𝐶_1$) = 𝜋, 𝑝($𝐶_2$) = 1 − 𝜋.\n",
        ">\n",
        "Для одной точки в классе $𝐶_1$:\n",
        ">\n",
        "$𝑝(x_𝑛, 𝐶_1) = 𝑝(𝐶_1)𝑝(x_𝑛 ∣ 𝐶_1) = 𝜋𝑁(x_𝑛 ∣ 𝜇_1, Σ)$\n",
        ">\n",
        "В классе $𝐶_2$:\n",
        ">\n",
        "$𝑝(x_𝑛, 𝐶_2) = 𝑝(𝐶_2)𝑝(x_𝑛 ∣ 𝐶_2) = (1 − 𝜋)𝑁(x_𝑛 ∣ 𝜇_2, Σ)$\n",
        ">\n",
        "Функция правдоподобия:\n",
        ">\n",
        "$𝑝(t ∣ 𝜋, 𝜇_1, 𝜇_2, Σ) =$\n",
        "$=\\prod^𝑁_{𝑛=1}[𝜋𝑁(x_𝑛 ∣ 𝜇_1, Σ)]^{𝑡_𝑛}[(1 − 𝜋)𝑁(x_𝑛 ∣ 𝜇_2, Σ)]^{1−𝑡_𝑛}$\n",
        ">\n",
        "Максимизируем логарифм правдоподобия. Сначала по 𝜋, там\n",
        "останется только\n",
        ">\n",
        "$∑^𝑁_{𝑛=1}[𝑡_𝑛 ln 𝜋 + (1 − 𝑡_𝑛)ln(1 − 𝜋)]$,\n",
        ">\n",
        "и, взяв производную, получим,\n",
        ">\n",
        "$\\hat{𝜋}=\\frac{𝑁_1}{𝑁1 + 𝑁2}$\n",
        ">\n",
        "Теперь по $𝜇_1$; всё, что зависит от $𝜇_1$:\n",
        ">\n",
        "$∑_𝑛 𝑡_𝑛 ln 𝑁(x_𝑛 ∣ 𝜇_1, Σ) = -\\frac{1}{2} \\sum\\limits_{n} 𝑡_𝑛 (x_𝑛 − 𝜇_1)^⊤ Σ^{−1} (x_𝑛 − 𝜇_1) + 𝐶$\n",
        ">\n",
        "Берём производную, и получается, что,\n",
        ">\n",
        "$\\hat{𝜇_1}=\\frac{1}{N_1} ∑^𝑁_{𝑛=1}𝑡_𝑛x_𝑛$\n",
        ">\n",
        "Аналогично,\n",
        ">\n",
        "$\\hat{𝜇_2}=\\frac{1}{N_2} ∑^𝑁_{𝑛=1}(1-𝑡_𝑛)x_𝑛$\n",
        ">\n",
        "В результате получится\n",
        "$\\hat{Σ}=\\frac{N_1}{N_1+N_2}S_1 +\\frac{N_2}{N_1+N_2}S_2$, \n",
        ">\n",
        "где\n",
        ">\n",
        "$S_1 = \\frac{1}{𝑁_1} \\sum\\limits_{n \\in C_1}(x_𝑛 − 𝜇_1) (x_𝑛 − 𝜇_1)^⊤$,\n",
        ">\n",
        "$S_2 = \\frac{1}{𝑁_2} \\sum\\limits_{n \\in C_2}(x_𝑛 − 𝜇_2) (x_𝑛 − 𝜇_2)^⊤$\n"
      ],
      "metadata": {
        "id": "pHs7-oU_XAnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для нормального распределения с плотностью вероятности $f(x|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$, где $\\mu$ - математическое ожидание, а $\\sigma^2$ - дисперсия, можно получить оценки параметров из принципа максимума правдоподобия.\n",
        "\n",
        "Предположим, что у нас есть выборка $X_1, X_2, ..., X_n$ из нормального распределения с неизвестными параметрами $\\mu$ и $\\sigma^2$. Тогда функция правдоподобия определяется как произведение вероятностей всех наблюдений, то есть:\n",
        "\n",
        "$L(\\mu, \\sigma^2 | x_1, x_2, ..., x_n) = \\prod_{i=1}^{n} f(x_i | \\mu, \\sigma^2)$\n",
        "\n",
        "Для удобства работы с этой функцией, можно прологарифмировать её:\n",
        "\n",
        "$\\ln L(\\mu, \\sigma^2 | x_1, x_2, ..., x_n) = \\sum_{i=1}^{n} \\ln f(x_i | \\mu, \\sigma^2)$\n",
        "\n",
        "Далее, используя свойства логарифма, можно переписать это выражение в более удобном виде:\n",
        "\n",
        "$\\ln L(\\mu, \\sigma^2 | x_1, x_2, ..., x_n) = -\\frac{n}{2} \\ln (2\\pi) -\\frac{n}{2} \\ln (\\sigma^2) -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2$\n",
        "\n",
        "Для нахождения оценок параметров, необходимо максимизировать функцию правдоподобия по $\\mu$ и $\\sigma^2$. В этом случае оценка максимального правдоподобия для $\\mu$ равна выборочному среднему:\n",
        "\n",
        "$\\hat{\\mu}_{ML} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$\n",
        "\n",
        "А оценка максимального правдоподобия для $\\sigma^2$ равна несмещённой выборочной дисперсии:\n",
        "\n",
        "$\\hat{\\sigma}^2_{ML} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\hat{\\mu}_{ML})^2$\n",
        "\n",
        "Здесь $\\hat{\\mu}_{ML}$ и $\\hat{\\sigma}^2_{ML}$ обозначают оценки максимального правдоподобия для $\\mu$ и $\\sigma^2$ соответственно."
      ],
      "metadata": {
        "id": "77Hnsv4P3IEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 3** (15 баллов) \n",
        "\n",
        "Постройте рекомендательную систему фильмов на датасете [Movie Lens](http://grouplens.org/datasets/movielens/). В качестве данных обучения можно использовать файлы с расширением base, а тестирование качества провести на файле test: пары файлов u1.base и u1.test, ..., u5.base и u5.test. Каждая пара -- это разбиение 80%/20%  данных для всех пользователей $u$ на обучащие и тестовые данные. \n",
        "\n",
        "Реализуйте вычисление ошибок MAE и RMSE, и постройте графики зависимости MAE и RMSE от числа соседей (диапазон от 1 до 100 с разумным шагом). \n",
        "Вопросы:\n",
        "1. Как изменяется величина MAE (RMSE) от числа выдаваемых рекомендаций (top-n): $n \\in \\{1,3,5,10,15,20,30,40,50,100\\}$? \n",
        "2. Как Вы считаете, какие фильмы чаще рекомендуются -- популярные с высокими оценками или редкие (те, которые редко оцениваются) с высокими оценками?\n",
        "3. Что делать, если соседей (то есть похожих на целевого пользователя или конкретный товар) мало? Нужно/можно ли как-то учитывать достоверность таких рекомендаций? \n",
        "\n",
        "Ниже некоторый вспомогательный код для работы с датасетом, который можно использовать в той или иной мере, а можно вообще убрать и написать по-своему. "
      ],
      "metadata": {
        "id": "KPXv_gXXc3xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -n ml-100k.zip"
      ],
      "metadata": {
        "id": "SOrSl7hmOYI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadMovieLens(path = 'ml-100k'): # Или, работая в google colab, сделайте по аналогии с семинарами / прошлыми домашними заданиями ввод данных \n",
        "\n",
        "# Получить названия фильмов\n",
        "    movies = {}\n",
        "    for line in open(path+'/u.item', encoding='latin-1'):\n",
        "        (id,title) = line.split('|')[0:2]\n",
        "        movies[id] = title\n",
        "\n",
        "# Загрузить данные\n",
        "    prefs={}\n",
        "    for line in open(path+'/u.data'):\n",
        "        (user,movieid,rating,ts)=line.split('\\t')\n",
        "        prefs.setdefault(user,{})\n",
        "        prefs[user][movies[movieid]]=float(rating)\n",
        "    return prefs"
      ],
      "metadata": {
        "id": "VoMMiPk8VmxD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefs=loadMovieLens( )\n",
        "prefs['87']"
      ],
      "metadata": {
        "id": "eOfnMtEscmmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82318788-8570-47b6-e18d-541c6b798847"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Naked Gun 33 1/3: The Final Insult (1994)': 4.0,\n",
              " 'Con Air (1997)': 4.0,\n",
              " 'Sabrina (1995)': 4.0,\n",
              " 'Waterworld (1995)': 4.0,\n",
              " 'To Wong Foo, Thanks for Everything! Julie Newmar (1995)': 3.0,\n",
              " 'Clueless (1995)': 4.0,\n",
              " 'Jurassic Park (1993)': 5.0,\n",
              " 'Brady Bunch Movie, The (1995)': 2.0,\n",
              " 'Son in Law (1993)': 4.0,\n",
              " 'Indiana Jones and the Last Crusade (1989)': 5.0,\n",
              " 'Good, The Bad and The Ugly, The (1966)': 5.0,\n",
              " 'Dead Poets Society (1989)': 5.0,\n",
              " 'Dead Man Walking (1995)': 4.0,\n",
              " \"Joe's Apartment (1996)\": 2.0,\n",
              " 'GoldenEye (1995)': 4.0,\n",
              " 'M*A*S*H (1970)': 5.0,\n",
              " 'Something to Talk About (1995)': 2.0,\n",
              " 'Lightning Jack (1994)': 3.0,\n",
              " 'Big Green, The (1995)': 3.0,\n",
              " 'Cowboy Way, The (1994)': 3.0,\n",
              " \"Ulee's Gold (1997)\": 3.0,\n",
              " 'Addams Family Values (1993)': 2.0,\n",
              " '2001: A Space Odyssey (1968)': 5.0,\n",
              " 'Platoon (1986)': 3.0,\n",
              " 'Return of the Pink Panther, The (1974)': 4.0,\n",
              " 'Four Weddings and a Funeral (1994)': 5.0,\n",
              " 'Under Siege (1992)': 4.0,\n",
              " 'Ace Ventura: Pet Detective (1994)': 4.0,\n",
              " 'Die Hard: With a Vengeance (1995)': 4.0,\n",
              " 'Prefontaine (1997)': 5.0,\n",
              " 'Cops and Robbersons (1994)': 3.0,\n",
              " \"Pyromaniac's Love Story, A (1995)\": 3.0,\n",
              " 'Glory (1989)': 4.0,\n",
              " 'This Is Spinal Tap (1984)': 5.0,\n",
              " 'Multiplicity (1996)': 3.0,\n",
              " 'Tommy Boy (1995)': 4.0,\n",
              " 'Cool Hand Luke (1967)': 5.0,\n",
              " \"Monty Python's Life of Brian (1979)\": 4.0,\n",
              " 'Victor/Victoria (1982)': 4.0,\n",
              " 'Treasure of the Sierra Madre, The (1948)': 4.0,\n",
              " 'That Old Feeling (1997)': 4.0,\n",
              " 'Mrs. Doubtfire (1993)': 4.0,\n",
              " 'Professional, The (1994)': 4.0,\n",
              " 'True Lies (1994)': 5.0,\n",
              " 'Air Force One (1997)': 3.0,\n",
              " 'Speechless (1994)': 4.0,\n",
              " 'Sleepless in Seattle (1993)': 5.0,\n",
              " 'Young Frankenstein (1974)': 5.0,\n",
              " 'GoodFellas (1990)': 4.0,\n",
              " 'Fugitive, The (1993)': 5.0,\n",
              " 'In the Line of Fire (1993)': 5.0,\n",
              " 'Reality Bites (1994)': 3.0,\n",
              " 'Shadow, The (1994)': 3.0,\n",
              " 'Speed (1994)': 5.0,\n",
              " 'Batman Returns (1992)': 3.0,\n",
              " 'Conan the Barbarian (1981)': 3.0,\n",
              " 'Terminator 2: Judgment Day (1991)': 5.0,\n",
              " 'Strange Days (1995)': 3.0,\n",
              " 'Star Trek III: The Search for Spock (1984)': 4.0,\n",
              " \"Schindler's List (1993)\": 4.0,\n",
              " 'Sneakers (1992)': 4.0,\n",
              " 'Twelve Monkeys (1995)': 4.0,\n",
              " 'Switchblade Sisters (1975)': 2.0,\n",
              " 'Searching for Bobby Fischer (1993)': 4.0,\n",
              " 'Birdcage, The (1996)': 4.0,\n",
              " \"Singin' in the Rain (1952)\": 4.0,\n",
              " 'Shawshank Redemption, The (1994)': 5.0,\n",
              " 'Santa Clause, The (1994)': 4.0,\n",
              " 'Clear and Present Danger (1994)': 5.0,\n",
              " 'Dances with Wolves (1990)': 5.0,\n",
              " 'Deer Hunter, The (1978)': 3.0,\n",
              " 'Boot, Das (1981)': 4.0,\n",
              " 'Alien (1979)': 4.0,\n",
              " 'Speed 2: Cruise Control (1997)': 3.0,\n",
              " 'Maverick (1994)': 3.0,\n",
              " 'Jack (1996)': 3.0,\n",
              " 'Desperado (1995)': 3.0,\n",
              " 'Nutty Professor, The (1996)': 4.0,\n",
              " 'Batman (1989)': 3.0,\n",
              " 'Dave (1993)': 4.0,\n",
              " 'Crow, The (1994)': 3.0,\n",
              " 'Adventures of Robin Hood, The (1938)': 5.0,\n",
              " 'Blues Brothers, The (1980)': 5.0,\n",
              " 'Adventures of Priscilla, Queen of the Desert, The (1994)': 3.0,\n",
              " 'Raging Bull (1980)': 3.0,\n",
              " 'Batman & Robin (1997)': 4.0,\n",
              " 'Babe (1995)': 5.0,\n",
              " 'Raising Arizona (1987)': 3.0,\n",
              " 'Cliffhanger (1993)': 3.0,\n",
              " 'Top Gun (1986)': 5.0,\n",
              " 'Endless Summer 2, The (1994)': 3.0,\n",
              " 'Barcelona (1994)': 3.0,\n",
              " 'Twister (1996)': 4.0,\n",
              " 'Evil Dead II (1987)': 2.0,\n",
              " 'Sleepers (1996)': 4.0,\n",
              " 'Striptease (1996)': 2.0,\n",
              " 'Get Shorty (1995)': 5.0,\n",
              " 'So I Married an Axe Murderer (1993)': 2.0,\n",
              " 'Mission: Impossible (1996)': 4.0,\n",
              " 'Wizard of Oz, The (1939)': 5.0,\n",
              " 'Baby-Sitters Club, The (1995)': 2.0,\n",
              " 'When Harry Met Sally... (1989)': 5.0,\n",
              " 'Mother (1996)': 2.0,\n",
              " 'Star Trek IV: The Voyage Home (1986)': 5.0,\n",
              " 'Swimming with Sharks (1995)': 3.0,\n",
              " 'Net, The (1995)': 5.0,\n",
              " 'Private Benjamin (1980)': 4.0,\n",
              " 'Fargo (1996)': 5.0,\n",
              " 'Dumb & Dumber (1994)': 4.0,\n",
              " 'Stargate (1994)': 5.0,\n",
              " \"City Slickers II: The Legend of Curly's Gold (1994)\": 3.0,\n",
              " 'Hoop Dreams (1994)': 4.0,\n",
              " 'Young Guns (1988)': 3.0,\n",
              " 'Groundhog Day (1993)': 5.0,\n",
              " 'Bridge on the River Kwai, The (1957)': 5.0,\n",
              " 'Braveheart (1995)': 4.0,\n",
              " 'Vegas Vacation (1997)': 4.0,\n",
              " 'Michael (1996)': 4.0,\n",
              " 'Star Trek: The Wrath of Khan (1982)': 5.0,\n",
              " 'Muppet Treasure Island (1996)': 3.0,\n",
              " 'Nine Months (1995)': 4.0,\n",
              " 'Die Hard (1988)': 4.0,\n",
              " 'Bananas (1971)': 5.0,\n",
              " 'Forget Paris (1995)': 4.0,\n",
              " 'French Kiss (1995)': 5.0,\n",
              " 'Truth About Cats & Dogs, The (1996)': 4.0,\n",
              " 'Empire Strikes Back, The (1980)': 5.0,\n",
              " 'Dunston Checks In (1996)': 1.0,\n",
              " 'Star Trek: The Motion Picture (1979)': 3.0,\n",
              " 'Return of the Jedi (1983)': 5.0,\n",
              " 'Manchurian Candidate, The (1962)': 4.0,\n",
              " 'River Wild, The (1994)': 4.0,\n",
              " 'House Arrest (1996)': 3.0,\n",
              " 'Milk Money (1994)': 4.0,\n",
              " 'Godfather, The (1972)': 4.0,\n",
              " 'Low Down Dirty Shame, A (1994)': 3.0,\n",
              " 'Butch Cassidy and the Sundance Kid (1969)': 5.0,\n",
              " 'Wyatt Earp (1994)': 3.0,\n",
              " 'Star Wars (1977)': 5.0,\n",
              " 'To Kill a Mockingbird (1962)': 4.0,\n",
              " 'Magnificent Seven, The (1954)': 5.0,\n",
              " 'Back to the Future (1985)': 5.0,\n",
              " 'Hot Shots! Part Deux (1993)': 4.0,\n",
              " 'Great White Hype, The (1996)': 3.0,\n",
              " \"Dante's Peak (1997)\": 3.0,\n",
              " 'Matilda (1996)': 3.0,\n",
              " 'Junior (1994)': 4.0,\n",
              " 'Blade Runner (1982)': 4.0,\n",
              " 'Mars Attacks! (1996)': 3.0,\n",
              " 'My Favorite Year (1982)': 3.0,\n",
              " 'Broken Arrow (1996)': 3.0,\n",
              " 'Young Guns II (1990)': 2.0,\n",
              " 'Terminator, The (1984)': 5.0,\n",
              " 'Fish Called Wanda, A (1988)': 5.0,\n",
              " 'Down Periscope (1996)': 4.0,\n",
              " 'Hard Target (1993)': 4.0,\n",
              " 'Ed Wood (1994)': 3.0,\n",
              " 'Demolition Man (1993)': 3.0,\n",
              " 'Mask, The (1994)': 3.0,\n",
              " 'E.T. the Extra-Terrestrial (1982)': 3.0,\n",
              " 'Coneheads (1993)': 4.0,\n",
              " 'Man of the House (1995)': 3.0,\n",
              " 'That Thing You Do! (1996)': 4.0,\n",
              " 'Strictly Ballroom (1992)': 3.0,\n",
              " \"It's a Wonderful Life (1946)\": 5.0,\n",
              " 'Annie Hall (1977)': 4.0,\n",
              " 'Dragonheart (1996)': 4.0,\n",
              " 'Renaissance Man (1994)': 5.0,\n",
              " 'Kingpin (1996)': 4.0,\n",
              " 'In the Army Now (1994)': 4.0,\n",
              " 'Mighty Aphrodite (1995)': 3.0,\n",
              " \"Weekend at Bernie's (1989)\": 3.0,\n",
              " 'Clockwork Orange, A (1971)': 4.0,\n",
              " 'Heat (1995)': 3.0,\n",
              " 'Addicted to Love (1997)': 4.0,\n",
              " 'Program, The (1993)': 3.0,\n",
              " 'Grumpier Old Men (1995)': 4.0,\n",
              " 'Bad Boys (1995)': 4.0,\n",
              " 'American President, The (1995)': 5.0,\n",
              " 'Grease (1978)': 4.0,\n",
              " 'Full Metal Jacket (1987)': 4.0,\n",
              " 'Air Up There, The (1994)': 3.0,\n",
              " 'Home Alone (1990)': 4.0,\n",
              " 'Jimmy Hollywood (1994)': 3.0,\n",
              " 'I.Q. (1994)': 5.0,\n",
              " 'First Wives Club, The (1996)': 2.0,\n",
              " 'Boomerang (1992)': 3.0,\n",
              " 'Heathers (1989)': 3.0,\n",
              " 'While You Were Sleeping (1995)': 5.0,\n",
              " 'Star Trek: First Contact (1996)': 4.0,\n",
              " 'Independence Day (ID4) (1996)': 5.0,\n",
              " 'Lost World: Jurassic Park, The (1997)': 3.0,\n",
              " 'Raiders of the Lost Ark (1981)': 5.0,\n",
              " 'To Die For (1995)': 3.0,\n",
              " 'I Love Trouble (1994)': 3.0,\n",
              " 'Citizen Kane (1941)': 4.0,\n",
              " 'Sleeper (1973)': 4.0,\n",
              " 'Quiet Man, The (1952)': 5.0,\n",
              " 'Sting, The (1973)': 5.0,\n",
              " 'Up in Smoke (1978)': 3.0,\n",
              " 'Executive Decision (1996)': 3.0,\n",
              " 'Jeffrey (1995)': 3.0,\n",
              " 'Inkwell, The (1994)': 3.0,\n",
              " 'Serial Mom (1994)': 1.0,\n",
              " 'Pulp Fiction (1994)': 4.0,\n",
              " 'Supercop (1992)': 3.0,\n",
              " 'Major Payne (1994)': 3.0,\n",
              " 'Big Squeeze, The (1996)': 2.0,\n",
              " 'Days of Thunder (1990)': 5.0,\n",
              " 'Apocalypse Now (1979)': 4.0}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(prefs['87'])"
      ],
      "metadata": {
        "id": "Naq53LpscogH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d333747-2fe2-4029-c987-9a577b683afc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "# Функция возвращает коэффициент корреляции Пирсона для p1 и p2\n",
        "def sim_pearson(prefs,p1,p2):\n",
        " # Получение списка взаимно оцененных предметов\n",
        " si={}\n",
        " for item in prefs[p1]:\n",
        "   if item in prefs[p2]:\n",
        "     si[item]=1\n",
        " # Найдем количество элементов\n",
        " n=len(si)\n",
        " # Если у них нет ни одной общей оценки, возвращаем 0\n",
        " if n==0:\n",
        "   return 0\n",
        " # Суммируем все предпочтения\n",
        " sum1=sum([prefs[p1][it] for it in si])\n",
        " sum2=sum([prefs[p2][it] for it in si])\n",
        " # Вычисляем сумму квадратов\n",
        " sum1Sq=sum([pow(prefs[p1][it],2) for it in si])\n",
        " sum2Sq=sum([pow(prefs[p2][it],2) for it in si])\n",
        " # Вычисляем сумму произведений\n",
        " pSum=sum([prefs[p1][it]*prefs[p2][it] for it in si])\n",
        " # Вычисляем коэффициент Пирсона\n",
        " num=pSum-(sum1*sum2/n)\n",
        " den=sqrt((sum1Sq-pow(sum1,2)/n)*(sum2Sq-pow(sum2,2)/n))\n",
        " if den==0:\n",
        "   return 0\n",
        " r=num/den\n",
        " return r"
      ],
      "metadata": {
        "id": "KYdhOuDmS-TM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем рекомендации для определенного человека, используя средневзвешенное значение оценок всех других пользователей\n",
        "def getRecommendations(prefs,person,similarity=sim_pearson):\n",
        "  totals={}\n",
        "  simSums={}\n",
        "  for other in prefs:\n",
        "    # не сравниваем с ним же \n",
        "    if other==person: continue\n",
        "    sim=similarity(prefs,person,other)\n",
        "    # игнорируем оценки ноль или меньше\n",
        "    if sim<=0: continue\n",
        "    for item in prefs[other]:\n",
        "      # оцениваем только непросмотренные человеком фильмы\n",
        "      if item not in prefs[person] or prefs[person][item]==0:\n",
        "        # Коэффициент подобия * оценка\n",
        "        totals.setdefault(item,0)\n",
        "        totals[item]+=prefs[other][item]*sim\n",
        "        # Сумма коэффициентов подобия\n",
        "        simSums.setdefault(item,0)\n",
        "        simSums[item]+=sim\n",
        "    # Нормализованный список\n",
        "    rankings=[(total/simSums[item],item) for item,total in totals.items()]\n",
        "    # Возвращаем отсортированный список\n",
        "    rankings.sort()\n",
        "    rankings.reverse()\n",
        "    return rankings"
      ],
      "metadata": {
        "id": "9t5j0wD_TpaV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformPrefs(prefs):\n",
        "  result={}\n",
        "  for person in prefs:\n",
        "    for item in prefs[person]:\n",
        "      result.setdefault(item,{})\n",
        "      \n",
        "      # Меняем местами предмет и человека\n",
        "      result[item][person]=prefs[person][item]\n",
        "  return result"
      ],
      "metadata": {
        "id": "WTZp7MgAVHW-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Возвращаем наилучшие совпадения для человека из словаря prefs. Количество результатов и функция сходства - необязательные параметры.\n",
        "def topMatches(prefs,person,n=5,similarity=sim_pearson):\n",
        "  scores=[(similarity(prefs,person,other),other)\n",
        "  for other in prefs if other!=person]\n",
        "  # Отсортируем список по убыванию\n",
        "  scores.sort()\n",
        "  scores.reverse()\n",
        "  return scores[0:n]"
      ],
      "metadata": {
        "id": "BeXvFDhvViNd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Возвращаем оценку подобия на основе расстояния для person1 и person2\n",
        "def sim_distance(prefs,person1,person2):\n",
        "  # Получаем список, оцененный обоими людьми\n",
        "  si={}\n",
        "  for item in prefs[person1]:\n",
        "    if item in prefs[person2]:\n",
        "      si[item]=1\n",
        "  # Если у них нет общих оценок, возвращаем 0\n",
        "  if len(si)==0:\n",
        "    return 0\n",
        "  # Складываем квадраты всех разностей\n",
        "  sum_of_squares = sum([pow(prefs[person1][item] - prefs[person2][item], 2) for item in prefs[person1] if item in prefs[person2]])\n",
        "  for item in prefs[person1]:\n",
        "    if item in prefs[person2]:\n",
        "      return 1/(1+sum_of_squares)"
      ],
      "metadata": {
        "id": "78CZRWnwVs2p"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateSimilarItems(prefs,n=10):\n",
        "\t# Создаем словарь, который содержит объекты, которые наиоблее похожи на него (для каждого объекта)\n",
        "\tresult={}\n",
        "\n",
        "\t# Инвертируем матрицу предпочтений, чтобы она была ориентирована на элементы\n",
        "\titemPrefs=transformPrefs(prefs)\n",
        "\tc=0\n",
        "\n",
        "\tfor item in itemPrefs:\n",
        "\t\t# Обновление статуса для больших наборов данных\n",
        "\t\tc+=1\n",
        "\t\tif c%100==0: print(\"%d / %d\" % (c,len(itemPrefs)))\n",
        "\n",
        "\t\t# Найдем наиболее похожие на указанный товары \n",
        "\t\tscores=topMatches(itemPrefs,item,n=10,similarity=sim_distance)\n",
        "\t\tresult[item]=scores\n",
        "\treturn result"
      ],
      "metadata": {
        "id": "5owlG_ngdQxO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getRecommendedItems(prefs,itemMatch,user):\n",
        "  userRatings=prefs[user]\n",
        "  scores={}\n",
        "  totalSim={}\n",
        "  # Перебор элементов, оцененных этим пользователем\n",
        "  for (item,rating) in userRatings.items():\n",
        "    # Перебор элементов, похожих на этот\n",
        "    for (similarity,item2) in itemMatch[item]:\n",
        "      # Игнорируем, если этот пользователь уже оценивал этот элемент\n",
        "      if item2 in userRatings: continue\n",
        "      # Взвешенная сумма оценок, умноженные на коэффициент подобия\n",
        "      scores.setdefault(item2,0)\n",
        "      scores[item2]+=similarity*rating\n",
        "      # Сумма всех коэффициентов подобия\n",
        "      totalSim.setdefault(item2,0)\n",
        "      totalSim[item2]+=similarity\n",
        "  # Делим каждую общую оценку на общий вес, чтобы получить среднее значение\n",
        "  rankings=[(score/totalSim[item],item) for item,score in scores.items( )]\n",
        "  # Возвращаем рейтинг отсортированный по убыванию\n",
        "  rankings.sort( )\n",
        "  rankings.reverse( )\n",
        "  return rankings"
      ],
      "metadata": {
        "id": "W8FwYqedeSOM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itemsim=calculateSimilarItems(prefs,n=50)"
      ],
      "metadata": {
        "id": "AAb7l6-Wcr18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7aa0d2-fb85-478b-afaf-2b0f01b1c1d9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 / 1664\n",
            "200 / 1664\n",
            "300 / 1664\n",
            "400 / 1664\n",
            "500 / 1664\n",
            "600 / 1664\n",
            "700 / 1664\n",
            "800 / 1664\n",
            "900 / 1664\n",
            "1000 / 1664\n",
            "1100 / 1664\n",
            "1200 / 1664\n",
            "1300 / 1664\n",
            "1400 / 1664\n",
            "1500 / 1664\n",
            "1600 / 1664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "itemsim[\"What's Eating Gilbert Grape (1993)\"]"
      ],
      "metadata": {
        "id": "qoQlteiYcvD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a22e1f0-154b-4c78-8bf2-6c1e88c70bed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1.0, 'Yankee Zulu (1994)'),\n",
              " (1.0, 'Woman in Question, The (1950)'),\n",
              " (1.0, 'Witness (1985)'),\n",
              " (1.0, \"Wend Kuuni (God's Gift) (1982)\"),\n",
              " (1.0, 'Vie est belle, La (Life is Rosey) (1987)'),\n",
              " (1.0, 'Vermont Is For Lovers (1992)'),\n",
              " (1.0, 'Van, The (1996)'),\n",
              " (1.0, 'Two or Three Things I Know About Her (1966)'),\n",
              " (1.0, 'Two Much (1996)'),\n",
              " (1.0, 'Two Deaths (1995)')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getRecommendedItems(prefs,itemsim,'87')[0:30]"
      ],
      "metadata": {
        "id": "Od0697Kgcw3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a41f9a6-672f-48a4-f2df-5916fc823047"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(5.0, \"What's Eating Gilbert Grape (1993)\"),\n",
              " (5.0, 'Temptress Moon (Feng Yue) (1996)'),\n",
              " (5.0, 'Street Fighter (1994)'),\n",
              " (5.0, 'Spice World (1997)'),\n",
              " (5.0, 'Sliding Doors (1998)'),\n",
              " (5.0, 'Shooting Fish (1997)'),\n",
              " (5.0, \"Roseanna's Grave (For Roseanna) (1997)\"),\n",
              " (5.0, 'Rendezvous in Paris (Rendez-vous de Paris, Les) (1995)'),\n",
              " (5.0, 'Reluctant Debutante, The (1958)'),\n",
              " (5.0, 'Police Story 4: Project S (Chao ji ji hua) (1993)'),\n",
              " (5.0, 'Palmetto (1998)'),\n",
              " (5.0, 'New York Cop (1996)'),\n",
              " (5.0, 'Love Is All There Is (1996)'),\n",
              " (5.0, 'Johns (1996)'),\n",
              " (5.0, 'Innocents, The (1961)'),\n",
              " (5.0, 'Hollow Reed (1996)'),\n",
              " (4.666666666666667, 'Stranger, The (1994)'),\n",
              " (4.6, 'So Dear to My Heart (1949)'),\n",
              " (4.6, 'Saint of Fort Washington, The (1993)'),\n",
              " (4.571428571428571, 'They Made Me a Criminal (1939)'),\n",
              " (4.533333333333333, 'Silence of the Palace, The (Saimt el Qusur) (1994)'),\n",
              " (4.5, 'True Crime (1995)'),\n",
              " (4.5, 'Traveller (1997)'),\n",
              " (4.5, 'Thousand Acres, A (1997)'),\n",
              " (4.5, 'Steel (1997)'),\n",
              " (4.5, 'Star Maps (1997)'),\n",
              " (4.5, 'Spanish Prisoner, The (1997)'),\n",
              " (4.5, \"Someone Else's America (1995)\"),\n",
              " (4.5, 'Shiloh (1997)'),\n",
              " (4.5, 'Sexual Life of the Belgians, The (1994)')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}
